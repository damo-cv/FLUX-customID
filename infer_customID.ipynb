{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from src.customID.pipeline_flux import FluxPipeline\n",
    "from src.customID.transformer_flux import FluxTransformer2DModel\n",
    "from src.customID.model import CustomIDModel\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "_DEVICE = \"cuda:0\"\n",
    "_DTYPE=torch.bfloat16\n",
    "model_path = \"pretrained_ckpt/flux.1-dev\" #you can also use `black-forest-labs/FLUX.1-dev`\n",
    "transformer = FluxTransformer2DModel.from_pretrained(model_path, subfolder=\"transformer\", torch_dtype=_DTYPE).to(_DEVICE)\n",
    "pipe = FluxPipeline.from_pretrained(model_path, transformer=transformer, torch_dtype=_DTYPE).to(_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_token=64\n",
    "trained_ckpt = \"pretrained_ckpt/FLUX-customID.pt\"\n",
    "customID_model = CustomIDModel(pipe, trained_ckpt, _DEVICE, _DTYPE, num_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=3\n",
    "gs= 3.5\n",
    "_seed=2024\n",
    "h=1024\n",
    "w=1024\n",
    "img_path = \"img/man1.jpg\"\n",
    "p=\"A man wearing a classic leather jacket leans against a vintage motorcycle, surrounded by autumn leaves swirling in the breeze.\"\n",
    "images = customID_model.generate(pil_image=img_path,\n",
    "                            prompt=p,\n",
    "                            num_samples=num_samples,\n",
    "                            height=h,\n",
    "                            width=w,\n",
    "                            seed=_seed,\n",
    "                            num_inference_steps=28,\n",
    "                            guidance_scale=gs)\n",
    "face_img=[Image.open(img_path).resize((h,w))]\n",
    "grid = image_grid(images, 1, num_samples)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
